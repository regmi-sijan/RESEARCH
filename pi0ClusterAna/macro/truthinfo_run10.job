# All local jobs are part of the vanilla universe.
Universe = vanilla

# The argument to pass to the executable.
Arguments = $(Process)

# Used to give jobs a directory with respect to file input and output.
Initialdir = /sphenix/user/sregmi/WORKING_AREA/truth_par_ana/pi0ClusterAna/macros

# The executable we want to run.
Executable = $(Initialdir)/truthinfo_run10.sh

# The job's stdout is sent to this file.
Output = $(Initialdir)/log/out/$(Process).out

# The job's stderr is sent to this file.
Error = $(Initialdir)/log/err/$(Process).err

# The condor log file for this job, useful when debugging.
Log = /tmp/sregmi/$(Process).log

# We want email if the job completed successfully. This can
# be set to Always, Complete, Error, or Never.
Notification = Error

# Email address to send notification to.
Notify_user = sr276419@ohio.edu


RequestMemory = 8000MB

#concurrency_limits=CONCURRENCY_LIMIT_DEFAULT:2300

# Preventing evicted jobs from holding up submission of other jobs
PeriodicHold = (NumJobStarts>=1 && JobStatus == 1)

# Transferring Output
# All files in the condor_scratch_dir will be transferred back to your Initialdir
#should_transfer_files = YES
#when_to_transfer_output = ON_EXIT_OR_EVICT

# This should be the last command and tells condor to queue the
# job.  If a number is placed after the command (i.e. Queue 15)
# then the job will be submitted N times.  Use the $(Process)
# macro to make your input/output and log files unique.

Queue 20000

